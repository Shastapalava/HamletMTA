{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling M100 Lateness\n",
    "\n",
    "Here we're trying to model the M100's lateness and simulated crowdedness in the St. Nicholas stop going to Inwood 220 St Via Amsterdam Via Bway. \n",
    "\n",
    "We are applying Datacamp's Decision-Tree for Classification\n",
    "\n",
    "## Table of Contents:\n",
    "1. [Data Cleaning](#data-cleaning)\n",
    "1. [Plotting a Chart for Sanity](#plotting-a-chart-for-sanity)\n",
    "1. [Saving our Progress](#saving-our-progress)\n",
    "1. [Model Training](#model-training)\\*\n",
    "1. [Data Cleaning](#data-cleaning)\\*\n",
    "\n",
    "\\* Not finished yet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "random_state = 20181112\n",
    "import datetime, math, glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding data from the M100 csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "df = pd.read_csv('M100_Aug_W125_st.csv', error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choosing the Best Classifier\n",
    "\n",
    "We want (a) regressor(s) that can predict the **wait time** and **crowding** of a bus at a specific stop with the inputs **hourly weather** and **time of day**. We would most likely have two models that predict each **wait time** and **crowding**.\n",
    "\n",
    "Here are our top picks for regressors:\n",
    "\n",
    "1. Gradient Boosting Machines ***(top pick)***:\n",
    "    - Why: GBMs are typically a composite model that combines the efforts of multiple weak models to create a strong model, and each additional weak model reduces the mean squared error (MSE) of the overall model. Our goal would be to minimize MSE to increase the accuracy of our predictions.\n",
    "\n",
    "1. Random Forest:\n",
    "    - Why: does not suffer from the overfitting like with Decision Trees. Instead of randomly choosing to split from just **hourly weather** and **time of day**, we can have two trees that randomly split from each and find the best model. \n",
    "\n",
    "1. Decision Trees:  \n",
    "    - Reduction in Standard Deviation (metric): This is a regression metric that measures how much weâ€™ve reduced our uncertainty by picking a split point. By picking the best split each time the greedy decision tree training algorithm tries to form decisions with as few splits as possible.  \n",
    "    - Hyperparameters:   \n",
    "        * Max depth: Limit our tree to a `n` depth to prevent overfitting.\n",
    "        \n",
    "\n",
    "Evaluating our model:\n",
    "\n",
    "Since we're creating regression models, we are interested in the ***mean squared error*** and ***R Squared***. The lower our ***R Squared*** the more accurate our model. We intend to use **K-fold cross validation** as well as a **holdout set** as we improve our model through hyperparameter tuning. \n",
    "\n",
    "    * Preventing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "What we need to do:  \n",
    "\n",
    "1. Clean and break up the time components (Hour, Mins, Secs) of the following:\n",
    "    * `RecordedAtTime`\n",
    "    * `ExpectedArrivalTime`\n",
    "    * `ScheduledArrivalTime`\n",
    "    \n",
    "2. Store features of interest:\n",
    "    * `RecordedAtTime`\n",
    "    * `VehicleLocation.Longitude`\n",
    "    * `VehicleLocation.Latitude`\n",
    "    * `DistanceFromStop`\n",
    "    * `ExpectedArrivalTime`\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['ScheduledArrivalTime'] = pd.to_datetime(df.ScheduledArrivalTime, errors='coerce')\n",
    "df.dropna()\n",
    "df['Scheduled_Hour'] = df['ScheduledArrivalTime'].dt.hour\n",
    "df['Scheduled_Minute'] = df['ScheduledArrivalTime'].dt.minute\n",
    "df['Scheduled_Seconds'] = df['ScheduledArrivalTime'].dt.second\n",
    "\n",
    "df['RecordedAtTime'] = pd.to_datetime(df.RecordedAtTime)\n",
    "df['Recorded_Hour'] = pd.to_datetime(df.RecordedAtTime).dt.hour\n",
    "df['Recorded_Minute'] = pd.to_datetime(df.RecordedAtTime).dt.minute\n",
    "df['Recorded_Seconds'] = pd.to_datetime(df.RecordedAtTime).dt.second\n",
    "\n",
    "df['ExpectedArrivalTime'] = pd.to_datetime(df.ExpectedArrivalTime)\n",
    "df['Expected_Hour'] = pd.to_datetime(df.ExpectedArrivalTime).dt.hour\n",
    "df['Expected_Minute'] = pd.to_datetime(df.ExpectedArrivalTime).dt.minute\n",
    "df['Expected_Seconds'] = pd.to_datetime(df.ExpectedArrivalTime).dt.second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RecordedAtTime               datetime64[ns]\n",
       "DirectionRef                          int64\n",
       "PublishedLineName                    object\n",
       "OriginName                           object\n",
       "OriginLat                           float64\n",
       "OriginLong                          float64\n",
       "DestinationName                      object\n",
       "DestinationLat                      float64\n",
       "DestinationLong                     float64\n",
       "VehicleRef                           object\n",
       "VehicleLocation.Latitude            float64\n",
       "VehicleLocation.Longitude           float64\n",
       "NextStopPointName                    object\n",
       "ArrivalProximityText                 object\n",
       "DistanceFromStop                    float64\n",
       "ExpectedArrivalTime          datetime64[ns]\n",
       "ScheduledArrivalTime         datetime64[ns]\n",
       "time_diff_bus                        object\n",
       "time_diff_bus_mins                    int64\n",
       "Scheduled_Hour                      float64\n",
       "Scheduled_Minute                    float64\n",
       "Scheduled_Seconds                   float64\n",
       "Recorded_Hour                         int64\n",
       "Recorded_Minute                       int64\n",
       "Recorded_Seconds                      int64\n",
       "Expected_Hour                         int64\n",
       "Expected_Minute                       int64\n",
       "Expected_Seconds                      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RecordedAtTime               89\n",
       "DirectionRef                 89\n",
       "PublishedLineName            89\n",
       "OriginName                   89\n",
       "OriginLat                    89\n",
       "OriginLong                   89\n",
       "DestinationName              89\n",
       "DestinationLat               89\n",
       "DestinationLong              89\n",
       "VehicleRef                   89\n",
       "VehicleLocation.Latitude     89\n",
       "VehicleLocation.Longitude    89\n",
       "NextStopPointName            89\n",
       "ArrivalProximityText         89\n",
       "DistanceFromStop             89\n",
       "ExpectedArrivalTime          89\n",
       "ScheduledArrivalTime         86\n",
       "time_diff_bus                88\n",
       "time_diff_bus_mins           89\n",
       "Scheduled_Hour               86\n",
       "Scheduled_Minute             86\n",
       "Scheduled_Seconds            86\n",
       "Recorded_Hour                89\n",
       "Recorded_Minute              89\n",
       "Recorded_Seconds             89\n",
       "Expected_Hour                89\n",
       "Expected_Minute              89\n",
       "Expected_Seconds             89\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                        86\n",
       "VehicleLocation.Longitude    86\n",
       "VehicleLocation.Latitude     86\n",
       "OriginLong                   86\n",
       "OriginLat                    86\n",
       "DistanceFromStop             86\n",
       "Recorded_Hour                86\n",
       "Scheduled_Hour               86\n",
       "Scheduled_Minute             86\n",
       "Scheduled_Seconds            86\n",
       "Recorded_Minute              86\n",
       "Recorded_Seconds             86\n",
       "time_diff_bus_mins           86\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = (['VehicleLocation.Longitude', \n",
    "             'VehicleLocation.Latitude', \n",
    "             'OriginLong',\n",
    "             'OriginLat',\n",
    "             'DistanceFromStop',\n",
    "             'Recorded_Hour',\n",
    "             'Scheduled_Hour',\n",
    "             'Scheduled_Minute',\n",
    "             'Scheduled_Seconds',\n",
    "             'Recorded_Minute',\n",
    "             'Recorded_Seconds',\n",
    "             'time_diff_bus_mins'\n",
    "            ])\n",
    "\n",
    "model_df = df[(features)].dropna().reset_index()\n",
    "\n",
    "model_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting a Chart for Sanity\n",
    "\n",
    "We want to have a frequency/histogram for each hour of the day and for each minute of the hour.\n",
    "\n",
    "Credit: David"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ecdf(inputSeries, label):\n",
    "    try:\n",
    "        x = np.sort(inputSeries)\n",
    "    except:\n",
    "        print(\"Warning: Series Unsorted\")\n",
    "        x = inputSeries\n",
    "    y = np.arange(1, len(x)+1) / len(x)\n",
    "    _ = plt.plot(x, y, marker='.', linestyle='none')\n",
    "    _ = plt.xlabel('Time Delta ({})'.format(label))\n",
    "    _ = plt.ylabel('ECDF')\n",
    "    plt.margins(0.02) # Keeps data off plot edges\n",
    "    plt.show()\n",
    "\n",
    "def hist(inputSeries, label):\n",
    "    plt.hist(inputSeries, bins=25, density=True)\n",
    "    _ = plt.xlabel('Time Delta ({})'.format(label))\n",
    "    _ = plt.ylabel('PDF')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recorded_Hour</th>\n",
       "      <th>time_diff_bus_mins</th>\n",
       "      <th>Recorded_Minute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>191</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>161</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Recorded_Hour  time_diff_bus_mins  Recorded_Minute\n",
       "0              7                   0               51\n",
       "1              7                   0               51\n",
       "2              7                   0               51\n",
       "3             11                 191                2\n",
       "4             13                 161               42"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M100_NICK_Avg = df[['Recorded_Hour','time_diff_bus_mins', 'Recorded_Minute']]\n",
    "M100_Hour = M100_NICK_Avg.groupby('Recorded_Hour').mean().dropna()\n",
    "M100_Min = M100_NICK_Avg.groupby('Recorded_Minute').mean().dropna()\n",
    "M100_NICK_Avg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nPZ0+0TBOrYwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1aa9e04dd30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAEKCAYAAAAvlUMdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJKmL/w8Skb2f9q+wcgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1aa9e04dd68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEKCAYAAAD5MJl4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1aa9e76e0f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ4AAAEKCAYAAAAiizNaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1aa9e790780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ecdf(M100_Hour['time_diff_bus_mins'], \"per Hour\")\n",
    "hist(M100_Hour['time_diff_bus_mins'], \"per Hour\")\n",
    "\n",
    "ecdf(M100_Min['time_diff_bus_mins'], \"per Minute\")\n",
    "hist(M100_Min['time_diff_bus_mins'], \"per Minute\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving our Progress/Merging Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-109-896ee7a0f4c7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'M100_4_month_W125_st_timesplit.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model_df' is not defined"
     ]
    }
   ],
   "source": [
    "model_df.to_csv('M100_4_month_W125_st_timesplit.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "weather = pd.read_csv('1401011.csv', error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Wrong number of items passed 2, placement implies 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2441\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2442\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2443\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'dates'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mset\u001b[1;34m(self, item, value, check)\u001b[0m\n\u001b[0;32m   3714\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3715\u001b[1;33m             \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3716\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2443\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2444\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2445\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'dates'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-2b0799723868>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mweather\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'dates'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweather\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'DATE'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpand\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   2329\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2330\u001b[0m             \u001b[1;31m# set column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2331\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2332\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2333\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   2396\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2397\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2398\u001b[1;33m         \u001b[0mNDFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2399\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2400\u001b[0m         \u001b[1;31m# check if we are modifying a copy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1758\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1759\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1760\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mset\u001b[1;34m(self, item, value, check)\u001b[0m\n\u001b[0;32m   3716\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3717\u001b[0m             \u001b[1;31m# This item wasn't present, just insert at end\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3718\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3719\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3720\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36minsert\u001b[1;34m(self, loc, item, value, allow_duplicates)\u001b[0m\n\u001b[0;32m   3817\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3818\u001b[0m         block = make_block(values=value, ndim=self.ndim,\n\u001b[1;32m-> 3819\u001b[1;33m                            placement=slice(loc, loc + 1))\n\u001b[0m\u001b[0;32m   3820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3821\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mblkno\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_fast_count_smallints\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_blknos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mmake_block\u001b[1;34m(values, placement, klass, ndim, dtype, fastpath)\u001b[0m\n\u001b[0;32m   2717\u001b[0m                      placement=placement, dtype=dtype)\n\u001b[0;32m   2718\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2719\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfastpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2720\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2721\u001b[0m \u001b[1;31m# TODO: flexible with index=None and/or items=None\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, values, ndim, fastpath, placement, **kwargs)\u001b[0m\n\u001b[0;32m   1842\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1843\u001b[0m         super(ObjectBlock, self).__init__(values, ndim=ndim, fastpath=fastpath,\n\u001b[1;32m-> 1844\u001b[1;33m                                           placement=placement, **kwargs)\n\u001b[0m\u001b[0;32m   1845\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1846\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, values, placement, ndim, fastpath)\u001b[0m\n\u001b[0;32m    113\u001b[0m             raise ValueError('Wrong number of items passed %d, placement '\n\u001b[0;32m    114\u001b[0m                              'implies %d' % (len(self.values),\n\u001b[1;32m--> 115\u001b[1;33m                                              len(self.mgr_locs)))\n\u001b[0m\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Wrong number of items passed 2, placement implies 1"
     ]
    }
   ],
   "source": [
    "weather['dates'] = weather['DATE'].str.split(' ', 1, expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "df = pd.read_csv('M100_Aug_W125_st.csv', error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting training and testing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newWeather = weather[['DATE','HOURLYVISIBILITY', 'HOURLYWindSpeed', 'HOURLYPrecip']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newWeather['HOUR'] = pd.to_datetime(weather['DATE']).dt.hour\n",
    "newWeather['DAY'] = pd.to_datetime(weather['DATE']).dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Time gate to August\n",
    "\n",
    "newWeather = newWeather[(newWeather['DATE'] > '2017-08-01') & (newWeather['DATE'] < '2017-09-01')].reset_index().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>DATE</th>\n",
       "      <th>HOURLYVISIBILITY</th>\n",
       "      <th>HOURLYWindSpeed</th>\n",
       "      <th>HOURLYPrecip</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>DAY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>114732</td>\n",
       "      <td>2017-08-01 05:51</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>114733</td>\n",
       "      <td>2017-08-01 06:51</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>114734</td>\n",
       "      <td>2017-08-01 07:51</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>114735</td>\n",
       "      <td>2017-08-01 08:51</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>114736</td>\n",
       "      <td>2017-08-01 09:51</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>114737</td>\n",
       "      <td>2017-08-01 10:51</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>114738</td>\n",
       "      <td>2017-08-01 11:51</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>114739</td>\n",
       "      <td>2017-08-01 12:51</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>114740</td>\n",
       "      <td>2017-08-01 13:51</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>114741</td>\n",
       "      <td>2017-08-01 14:51</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>114742</td>\n",
       "      <td>2017-08-01 15:51</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>114743</td>\n",
       "      <td>2017-08-01 16:51</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>114744</td>\n",
       "      <td>2017-08-01 17:51</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>114745</td>\n",
       "      <td>2017-08-01 18:51</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>114746</td>\n",
       "      <td>2017-08-01 19:51</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>114757</td>\n",
       "      <td>2017-08-02 05:51</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>114758</td>\n",
       "      <td>2017-08-02 06:51</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>114759</td>\n",
       "      <td>2017-08-02 07:51</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>114760</td>\n",
       "      <td>2017-08-02 08:51</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34</td>\n",
       "      <td>114761</td>\n",
       "      <td>2017-08-02 09:51</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>114762</td>\n",
       "      <td>2017-08-02 10:51</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36</td>\n",
       "      <td>114763</td>\n",
       "      <td>2017-08-02 11:51</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37</td>\n",
       "      <td>114764</td>\n",
       "      <td>2017-08-02 12:51</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>38</td>\n",
       "      <td>114765</td>\n",
       "      <td>2017-08-02 13:51</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39</td>\n",
       "      <td>114766</td>\n",
       "      <td>2017-08-02 14:51</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>40</td>\n",
       "      <td>114767</td>\n",
       "      <td>2017-08-02 15:51</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>41</td>\n",
       "      <td>114768</td>\n",
       "      <td>2017-08-02 16:46</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>42</td>\n",
       "      <td>114769</td>\n",
       "      <td>2017-08-02 16:51</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>43</td>\n",
       "      <td>114770</td>\n",
       "      <td>2017-08-02 16:58</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>44</td>\n",
       "      <td>114771</td>\n",
       "      <td>2017-08-02 17:51</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>946</td>\n",
       "      <td>115673</td>\n",
       "      <td>2017-08-29 18:51</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>947</td>\n",
       "      <td>115674</td>\n",
       "      <td>2017-08-29 19:51</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>961</td>\n",
       "      <td>115688</td>\n",
       "      <td>2017-08-30 05:51</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>962</td>\n",
       "      <td>115689</td>\n",
       "      <td>2017-08-30 06:51</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>963</td>\n",
       "      <td>115690</td>\n",
       "      <td>2017-08-30 07:51</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>964</td>\n",
       "      <td>115691</td>\n",
       "      <td>2017-08-30 08:51</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>965</td>\n",
       "      <td>115692</td>\n",
       "      <td>2017-08-30 09:51</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>966</td>\n",
       "      <td>115693</td>\n",
       "      <td>2017-08-30 10:51</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>967</td>\n",
       "      <td>115694</td>\n",
       "      <td>2017-08-30 11:51</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>968</td>\n",
       "      <td>115695</td>\n",
       "      <td>2017-08-30 12:51</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>969</td>\n",
       "      <td>115696</td>\n",
       "      <td>2017-08-30 13:51</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>971</td>\n",
       "      <td>115698</td>\n",
       "      <td>2017-08-30 15:51</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>972</td>\n",
       "      <td>115699</td>\n",
       "      <td>2017-08-30 16:51</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>973</td>\n",
       "      <td>115700</td>\n",
       "      <td>2017-08-30 17:51</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>974</td>\n",
       "      <td>115701</td>\n",
       "      <td>2017-08-30 18:51</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>975</td>\n",
       "      <td>115702</td>\n",
       "      <td>2017-08-30 19:51</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770</th>\n",
       "      <td>986</td>\n",
       "      <td>115713</td>\n",
       "      <td>2017-08-31 05:51</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>987</td>\n",
       "      <td>115714</td>\n",
       "      <td>2017-08-31 06:51</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>988</td>\n",
       "      <td>115715</td>\n",
       "      <td>2017-08-31 07:51</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>989</td>\n",
       "      <td>115716</td>\n",
       "      <td>2017-08-31 08:51</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>991</td>\n",
       "      <td>115718</td>\n",
       "      <td>2017-08-31 10:51</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>992</td>\n",
       "      <td>115719</td>\n",
       "      <td>2017-08-31 11:51</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>993</td>\n",
       "      <td>115720</td>\n",
       "      <td>2017-08-31 12:51</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>994</td>\n",
       "      <td>115721</td>\n",
       "      <td>2017-08-31 13:51</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>995</td>\n",
       "      <td>115722</td>\n",
       "      <td>2017-08-31 14:51</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>996</td>\n",
       "      <td>115723</td>\n",
       "      <td>2017-08-31 15:51</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>997</td>\n",
       "      <td>115724</td>\n",
       "      <td>2017-08-31 16:51</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>998</td>\n",
       "      <td>115725</td>\n",
       "      <td>2017-08-31 17:51</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>999</td>\n",
       "      <td>115726</td>\n",
       "      <td>2017-08-31 18:51</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>1000</td>\n",
       "      <td>115727</td>\n",
       "      <td>2017-08-31 19:51</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>505 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     level_0   index              DATE  HOURLYVISIBILITY  HOURLYWindSpeed  \\\n",
       "5          5  114732  2017-08-01 05:51              10.0              0.0   \n",
       "6          6  114733  2017-08-01 06:51              10.0              0.0   \n",
       "7          7  114734  2017-08-01 07:51              10.0              5.0   \n",
       "8          8  114735  2017-08-01 08:51              10.0              6.0   \n",
       "9          9  114736  2017-08-01 09:51              10.0              0.0   \n",
       "10        10  114737  2017-08-01 10:51              10.0              3.0   \n",
       "11        11  114738  2017-08-01 11:51              10.0              5.0   \n",
       "12        12  114739  2017-08-01 12:51              10.0              3.0   \n",
       "13        13  114740  2017-08-01 13:51              10.0              3.0   \n",
       "14        14  114741  2017-08-01 14:51              10.0              0.0   \n",
       "15        15  114742  2017-08-01 15:51              10.0              5.0   \n",
       "16        16  114743  2017-08-01 16:51              10.0              3.0   \n",
       "17        17  114744  2017-08-01 17:51              10.0              5.0   \n",
       "18        18  114745  2017-08-01 18:51              10.0              5.0   \n",
       "19        19  114746  2017-08-01 19:51              10.0              5.0   \n",
       "29        30  114757  2017-08-02 05:51               7.0              0.0   \n",
       "30        31  114758  2017-08-02 06:51               7.0              0.0   \n",
       "31        32  114759  2017-08-02 07:51               7.0              0.0   \n",
       "32        33  114760  2017-08-02 08:51               6.0              0.0   \n",
       "33        34  114761  2017-08-02 09:51               8.0              0.0   \n",
       "34        35  114762  2017-08-02 10:51               9.0              6.0   \n",
       "35        36  114763  2017-08-02 11:51               6.0              5.0   \n",
       "36        37  114764  2017-08-02 12:51               7.0              0.0   \n",
       "37        38  114765  2017-08-02 13:51               8.0              0.0   \n",
       "38        39  114766  2017-08-02 14:51               7.0              3.0   \n",
       "39        40  114767  2017-08-02 15:51               5.0              9.0   \n",
       "40        41  114768  2017-08-02 16:46               1.0              5.0   \n",
       "41        42  114769  2017-08-02 16:51               2.0              3.0   \n",
       "42        43  114770  2017-08-02 16:58               5.0              3.0   \n",
       "43        44  114771  2017-08-02 17:51               6.0              0.0   \n",
       "..       ...     ...               ...               ...              ...   \n",
       "736      946  115673  2017-08-29 18:51              10.0              9.0   \n",
       "737      947  115674  2017-08-29 19:51               8.0              8.0   \n",
       "748      961  115688  2017-08-30 05:51              10.0              7.0   \n",
       "749      962  115689  2017-08-30 06:51              10.0              7.0   \n",
       "750      963  115690  2017-08-30 07:51              10.0              5.0   \n",
       "751      964  115691  2017-08-30 08:51              10.0              8.0   \n",
       "752      965  115692  2017-08-30 09:51              10.0              7.0   \n",
       "753      966  115693  2017-08-30 10:51              10.0              3.0   \n",
       "754      967  115694  2017-08-30 11:51              10.0              6.0   \n",
       "755      968  115695  2017-08-30 12:51              10.0              5.0   \n",
       "756      969  115696  2017-08-30 13:51              10.0              0.0   \n",
       "757      971  115698  2017-08-30 15:51              10.0              5.0   \n",
       "758      972  115699  2017-08-30 16:51              10.0              7.0   \n",
       "759      973  115700  2017-08-30 17:51              10.0              5.0   \n",
       "760      974  115701  2017-08-30 18:51              10.0              6.0   \n",
       "761      975  115702  2017-08-30 19:51              10.0              5.0   \n",
       "770      986  115713  2017-08-31 05:51              10.0              0.0   \n",
       "771      987  115714  2017-08-31 06:51              10.0              6.0   \n",
       "772      988  115715  2017-08-31 07:51              10.0              7.0   \n",
       "773      989  115716  2017-08-31 08:51              10.0              5.0   \n",
       "774      991  115718  2017-08-31 10:51              10.0              0.0   \n",
       "775      992  115719  2017-08-31 11:51              10.0              6.0   \n",
       "776      993  115720  2017-08-31 12:51              10.0              7.0   \n",
       "777      994  115721  2017-08-31 13:51              10.0              3.0   \n",
       "778      995  115722  2017-08-31 14:51              10.0              6.0   \n",
       "779      996  115723  2017-08-31 15:51              10.0              0.0   \n",
       "780      997  115724  2017-08-31 16:51              10.0              7.0   \n",
       "781      998  115725  2017-08-31 17:51              10.0              3.0   \n",
       "782      999  115726  2017-08-31 18:51              10.0              7.0   \n",
       "783     1000  115727  2017-08-31 19:51               9.0              0.0   \n",
       "\n",
       "     HOURLYPrecip  HOUR  DAY  \n",
       "5            0.00     5    1  \n",
       "6            0.00     6    1  \n",
       "7            0.00     7    1  \n",
       "8            0.00     8    1  \n",
       "9            0.00     9    1  \n",
       "10           0.00    10    1  \n",
       "11           0.00    11    1  \n",
       "12           0.00    12    1  \n",
       "13           0.00    13    1  \n",
       "14           0.00    14    1  \n",
       "15           0.00    15    1  \n",
       "16           0.00    16    1  \n",
       "17           0.00    17    1  \n",
       "18           0.00    18    1  \n",
       "19           0.00    19    1  \n",
       "29           0.00     5    2  \n",
       "30           0.00     6    2  \n",
       "31           0.00     7    2  \n",
       "32           0.00     8    2  \n",
       "33           0.00     9    2  \n",
       "34           0.00    10    2  \n",
       "35            NaN    11    2  \n",
       "36            NaN    12    2  \n",
       "37           0.00    13    2  \n",
       "38           0.00    14    2  \n",
       "39           0.01    15    2  \n",
       "40           0.07    16    2  \n",
       "41           0.08    16    2  \n",
       "42            NaN    16    2  \n",
       "43            NaN    17    2  \n",
       "..            ...   ...  ...  \n",
       "736          0.01    18    1  \n",
       "737          0.02    19    1  \n",
       "748          0.00     5    2  \n",
       "749          0.00     6    2  \n",
       "750          0.00     7    2  \n",
       "751          0.00     8    2  \n",
       "752          0.00     9    2  \n",
       "753          0.00    10    2  \n",
       "754          0.00    11    2  \n",
       "755          0.00    12    2  \n",
       "756          0.00    13    2  \n",
       "757          0.00    15    2  \n",
       "758          0.00    16    2  \n",
       "759          0.00    17    2  \n",
       "760          0.00    18    2  \n",
       "761          0.00    19    2  \n",
       "770          0.00     5    3  \n",
       "771          0.00     6    3  \n",
       "772          0.00     7    3  \n",
       "773          0.00     8    3  \n",
       "774          0.00    10    3  \n",
       "775          0.00    11    3  \n",
       "776          0.00    12    3  \n",
       "777          0.00    13    3  \n",
       "778          0.00    14    3  \n",
       "779          0.00    15    3  \n",
       "780          0.00    16    3  \n",
       "781          0.00    17    3  \n",
       "782          0.00    18    3  \n",
       "783          0.00    19    3  \n",
       "\n",
       "[505 rows x 8 columns]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Fix some data types\n",
    "newWeather['HOURLYPrecip'] = pd.to_numeric(newWeather['HOURLYPrecip'], downcast='float', errors='coerce')\n",
    "newWeather['HOURLYVISIBILITY'] = pd.to_numeric(newWeather['HOURLYVISIBILITY'], downcast='float', errors='coerce')\n",
    "# Bound hour of day\n",
    "newWeather = newWeather[(newWeather['HOUR'] > 4) & (newWeather['HOUR'] < 20)]\n",
    "newWeather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "level_0               int64\n",
       "index                 int64\n",
       "DATE                 object\n",
       "HOURLYVISIBILITY    float32\n",
       "HOURLYWindSpeed     float64\n",
       "HOURLYPrecip        float32\n",
       "HOUR                  int64\n",
       "DAY                   int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newWeather.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8     39\n",
       "10    37\n",
       "12    36\n",
       "6     35\n",
       "17    34\n",
       "9     34\n",
       "7     34\n",
       "19    33\n",
       "18    33\n",
       "14    33\n",
       "16    32\n",
       "15    32\n",
       "13    32\n",
       "5     32\n",
       "11    29\n",
       "Name: HOUR, dtype: int64"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newWeather['HOUR'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "\n",
    "Adapted from: https://shankarmsy.github.io/stories/gbrt-sklearn.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing required Python packages \n",
    "%matplotlib inline \n",
    "import matplotlib.pylab as plt \n",
    "import numpy as np \n",
    "from scipy import sparse \n",
    "from sklearn.datasets import make_classification, make_blobs, load_boston, fetch_california_housing \n",
    "from sklearn.decomposition import PCA \n",
    "from sklearn.cross_validation import ShuffleSplit, train_test_split \n",
    "from sklearn import metrics \n",
    "from sklearn.learning_curve import learning_curve \n",
    "from sklearn.linear_model import LinearRegression \n",
    "from sklearn.ensemble import GradientBoostingRegressor \n",
    "from sklearn.grid_search import GridSearchCV \n",
    "from pprint import pprint \n",
    "import pandas as pd \n",
    "from pandas.tools.plotting import scatter_matrix \n",
    "import urllib \n",
    "import requests \n",
    "import zipfile \n",
    "import seaborn \n",
    "\n",
    "np.random.seed(sum(map(ord, \"aesthetics\"))) \n",
    "seaborn.set_context('notebook') \n",
    "pd.set_option('display.mpl_style', 'default') # Make the graphs a bit prettier \n",
    "plt.rcParams['figure.figsize'] = (15, 5) # Set some Pandas options \n",
    "pd.set_option('display.notebook_repr_html', False) \n",
    "pd.set_option('display.max_columns', 40) \n",
    "pd.set_option('display.max_rows', 25) \n",
    "pd.options.display.max_colwidth = 50 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features, Targets and Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Cal. housing from https://ndownloader.figshare.com/files/5976036 to C:\\Users\\Excel\\scikit_learn_data\n"
     ]
    }
   ],
   "source": [
    "cal=fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Split data here\n",
    "X_train, X_test, y_train, y_test = train_test_split(cal.data, cal.target) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Gradient Boosting Regression Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbrt=GradientBoostingRegressor(n_estimators=100) \n",
    "\n",
    "gbrt.fit(X_train, y_train) \n",
    "y_pred=gbrt.predict(X_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Designing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " def GradientBooster(param_grid, n_jobs): \n",
    "        estimator = GradientBoostingRegressor() \n",
    "        #Choose cross-validation generator - let's choose ShuffleSplit which randomly shuffles and selects Train and CV sets \n",
    "        #for each iteration. There are other methods like the KFold split. \n",
    "        cv = ShuffleSplit(X_train.shape[0], n_iter=10, test_size=0.2) \n",
    "        \n",
    "        #Apply the cross-validation iterator on the Training set using GridSearchCV. This will run the classifier on the \n",
    "        #different train/cv splits using parameters specified and return the model that has the best results \n",
    "        #Note that we are tuning based on the F1 score 2PR/P+R where P is Precision and R is Recall. This may not always be \n",
    "        #the best score to tune our model on. I will explore this area further in a seperate exercise. For now, we'll use F1. \n",
    "        \n",
    "        classifier = GridSearchCV(estimator=estimator, cv=cv, param_grid=param_grid, n_jobs=n_jobs) \n",
    "        #Also note that we're feeding multiple neighbors to the GridSearch to try out. \n",
    "        #We'll now fit the training dataset to this classifier \n",
    "        classifier.fit(X_train, y_train) \n",
    "        \n",
    "        #Let's look at the best estimator that was found by GridSearchCV \n",
    "        print(\"Best Estimator learned through GridSearch\") \n",
    "        print(classifier.best_estimator_) \n",
    "        return cv, classifier.best_estimator_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    }
   ],
   "source": [
    "#Below is a plot_learning_curve module that's provided by scikit-learn. It allows us to quickly and easily visualize how #well the model is performing based on number of samples we're training on. It helps to understand situations such as #high variance or bias. \n",
    "#We'll call this module in the next segment. \n",
    "print(__doc__) \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn import cross_validation \n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.datasets import load_digits \n",
    "from sklearn.learning_curve import learning_curve \n",
    "\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None, n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)): \n",
    "    \"\"\" Generate a simple plot of the test and traning learning curve. \n",
    "    \n",
    "    Parameters \n",
    "    ---------- \n",
    "    estimator : \n",
    "    object type that implements the \"fit\" and \"predict\" methods An object of that type which is cloned for \n",
    "    each validation. title : string Title for the chart. X : array-like, shape (n_samples, n_features) \n",
    "    Training vector, where n_samples is the number of samples and n_features is the number of features. \n",
    "    y : \n",
    "    array-like, shape (n_samples) or (n_samples, n_features), optional Target relative to X for classification \n",
    "    or regression; None for unsupervised learning. ylim : tuple, shape (ymin, ymax), optional Defines minimum \n",
    "    and maximum yvalues plotted. cv : integer, cross-validation generator, optional If an integer is passed, \n",
    "    it is the number of folds (defaults to 3). Specific cross-validation objects can be passed, \n",
    "    see sklearn.cross_validation module for the list of possible objects n_jobs : integer, \n",
    "    optional Number of jobs to run in parallel (default 1). \"\"\" \n",
    "    \n",
    "    plt.figure() \n",
    "    plt.title(title) \n",
    "    if ylim is not None: \n",
    "        plt.ylim(*ylim) \n",
    "    plt.xlabel(\"Training examples\") \n",
    "    plt.ylabel(\"Score\") \n",
    "    train_sizes, train_scores, test_scores = learning_curve( estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes) \n",
    "    train_scores_mean = np.mean(train_scores, axis=1) \n",
    "    train_scores_std = np.std(train_scores, axis=1) \n",
    "    test_scores_mean = np.mean(test_scores, axis=1) \n",
    "    test_scores_std = np.std(test_scores, axis=1) \n",
    "    plt.grid() \n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color=\"r\") \n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color=\"g\") \n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\") \n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\") \n",
    "    plt.legend(loc=\"best\") \n",
    "    \n",
    "    return plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Estimator learned through GridSearch\n",
      "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "             learning_rate=0.1, loss='ls', max_depth=6, max_features=1.0,\n",
      "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "             min_impurity_split=None, min_samples_leaf=3,\n",
      "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "             n_estimators=100, presort='auto', random_state=None,\n",
      "             subsample=1.0, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "#WARNING - THIS MIGHT TAKE A WHILE TO RUN. TRY ADJUSTING parameters such as n_jobs (jobs to run in parallel, before \n",
    "#increasing this make sure your system can handle it), n_iter for ShuffleSplit (in the function definition) and reducing \n",
    "#number of values being tried for max_depth/n_estimators. \n",
    "#SELECT INTERRUPT IN THE MENU AND PRESS INTERRUPT KERNEL IF YOU NEEDD TO STOP EXECUTION \n",
    "\n",
    "param_grid={\n",
    "    'n_estimators':[100], \n",
    "    'learning_rate': [0.1],# 0.05, 0.02, 0.01], \n",
    "    'max_depth':[6],#4,6], \n",
    "    'min_samples_leaf':[3],#,5,9,17], \n",
    "    'max_features':[1.0],#,0.3]#,0.1] \n",
    "} \n",
    "\n",
    "n_jobs=4 \n",
    "#Let's fit GBRT to the digits training dataset by calling the function we just created. \n",
    "\n",
    "cv,best_est=GradientBooster(param_grid, n_jobs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Estimator Parameters\n",
      "---------------------------\n",
      "n_estimators: 100\n",
      "max_depth: 6\n",
      "Learning Rate: 0.1\n",
      "min_samples_leaf: 3\n",
      "max_features: 1.0\n",
      "Train R-squared: 0.9033749663\n"
     ]
    }
   ],
   "source": [
    "#OK great, so we got back the best estimator parameters as follows:\n",
    "print(\"Best Estimator Parameters\")\n",
    "print(\"---------------------------\")\n",
    "print(\"n_estimators:\", best_est.n_estimators)\n",
    "print(\"max_depth:\", best_est.max_depth)\n",
    "print(\"Learning Rate:\", best_est.learning_rate)\n",
    "print(\"min_samples_leaf:\", best_est.min_samples_leaf)\n",
    "print(\"max_features:\", best_est.max_features)\n",
    "\n",
    "print(\"Train R-squared:\", best_est.score(X_train,y_train))\n",
    "\n",
    "#Each of these parameters is critical to learning. Some of them will help address overfitting issues as well. For more \n",
    "#info about overfitting and regularization, check out the SVM notebook in my Github repos where I provide more info on \n",
    "#the subject.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The module simply runs the estimator multiple times on subsets of the data provided and plots the train and cv scores.\n",
    "#Note that we're feeding the best parameters we've learned from GridSearchCV to the estimator now.\n",
    "#We may need to adjust the hyperparameters further if there is overfitting (or underfitting, though unlikely)\n",
    "title = \"Learning Curves (Gradient Boosted Regression Trees)\" \n",
    "estimator = GradientBoostingRegressor(n_estimators=best_est.n_estimators, max_depth=best_est.max_depth,\n",
    "                                      learning_rate=best_est.learning_rate, min_samples_leaf=best_est.min_samples_leaf,\n",
    "                                      max_features=best_est.max_features)\n",
    "plot_learning_curve(estimator, title, X_train, y_train, cv=cv, n_jobs=n_jobs)\n",
    "plt.show()\n",
    "\n",
    "#Looks like we've done a reasonable job getting about ~0.85 R-squared on the cv set and looks from the learning\n",
    "#curve that we may be able to do a bit better with more estimators. Although we may need to reduce the learning rate even \n",
    "#further to address any overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Let's try one more trick. We'll trim the training set to its most important features and re-train to see if \n",
    "#that helps.\n",
    "title = \"Learning Curves (Gradient Boosted Regression Trees)\" \n",
    "\n",
    "#Dropping all parameters except n_estimators and learning_rate since we're going to trim the features anyway.\n",
    "estimator = GradientBoostingRegressor(n_estimators=best_est.n_estimators, learning_rate=best_est.learning_rate)\n",
    "\n",
    "#Calling fit on the estimator so we can transform the X matrices.\n",
    "estimator.fit(X_train, y_train)\n",
    "\n",
    "#Trimming feature matrices to include only those features that are more important than the mean of all importances.\n",
    "X_train_trim=estimator.transform(X_train, threshold='mean')\n",
    "\n",
    "#Trimming test as well in case we end up going with this model as final.\n",
    "X_test_trim=estimator.transform(X_test, threshold='mean')\n",
    "\n",
    "#Re-plotting Learning cruves.\n",
    "plot_learning_curve(estimator, title, X_train, y_train, cv=cv, n_jobs=n_jobs)\n",
    "plt.show()\n",
    "\n",
    "#So what do we infer from this plot? We seem to have addressed overfitting much better but the overall score of both train\n",
    "#and cv has gone down considerably, indicating that the features we dropped were actually collectively contributing\n",
    "#to the model. Let's go back to the first model that the Grid Search returned and run our test scores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Switching back to the best model from gridsearch\n",
    "estimator = best_est\n",
    "\n",
    "#Re-fitting to the train set\n",
    "estimator.fit(X_train, y_train)\n",
    "\n",
    "#Calculating train/test scores - R-squared value\n",
    "print(\"Train R-squared: \", estimator.score(X_train, y_train))\n",
    "print(\"Test R-squared: \", estimator.score(X_test, y_test))\n",
    "\n",
    "#There you have it, our final R-squared on the California housing dataset, 0.82"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#OK let's run through a more complex example this time. We'll explore anonymous loan data provided by lendingclub. \n",
    "#We'll try to predict the interest rate for loan applications based on data provided. Let's first download data to \n",
    "#a pandas df.\n",
    "\n",
    "#The Dataset is a zip file. So let's first read in the dataset through requests then pass it on to Pandas through the\n",
    "#read_csv command\n",
    "url=requests.get('https://resources.lendingclub.com/LoanStats3c.csv.zip')\n",
    "z=zipfile.ZipFile(StringIO.StringIO(url.content))\n",
    "\n",
    "loan=pd.read_csv(z.open('LoanStats3c.csv'), skiprows=1, parse_dates=True, index_col='id')\n",
    "loanbk=loan.copy() #Backup of the dataframe so we don't have to download data everytime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Let's take a quick peek at the dataset\n",
    "loan.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#For simplicity, let's first drop nulls in the dataset. axis=1 indicates we'll drop rows not cols.\n",
    "loan = loan.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#OK let's take a look at the columns and see if there are any we can drop any before we get started.\n",
    "loan.columns.values\n",
    "\n",
    "#There're plenty that don't seem very relevant. Let's drop them.\n",
    "loan=loan.drop(['member_id', 'grade', 'sub_grade', 'emp_title', 'issue_d',\n",
    "          'pymnt_plan', 'url', 'desc', 'title', 'initial_list_status',\n",
    "          'last_pymnt_d', 'last_pymnt_amnt', 'next_pymnt_d', 'last_credit_pull_d',\n",
    "          'policy_code', 'emp_length', 'addr_state','zip_code'], axis=1)\n",
    "\n",
    "#Check the data dictionary for this dataset at https://resources.lendingclub.com/LCDataDictionary.xlsx for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get rid of non-numeric values throughout the DataFrame:\n",
    "for col in loan.columns.values:\n",
    "  loan[col] = loan[col].replace('[^0-9]+.-', '', regex=True)\n",
    "loan.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Remove % symbol from the interest rate & revolving utilization\n",
    "loan.int_rate=loan.int_rate.str.split('%',1).str[0]\n",
    "loan.revol_util=loan.revol_util.str.split('%',1).str[0]\n",
    "\n",
    "#Remove \"months\" from the loan period\n",
    "loan.term=loan.term.str.split(' ',2).str[1]\n",
    "\n",
    "loan.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Let's change the Income Verified column, which currently has textual labels to numeric.\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "loan.is_inc_v = le.fit_transform(loan.is_inc_v.values)\n",
    "loan.home_ownership=le.fit_transform(loan.home_ownership.values)\n",
    "loan.loan_status=le.fit_transform(loan.loan_status.values)\n",
    "loan.purpose=le.fit_transform(loan.purpose.values)\n",
    "\n",
    "#Finally let's be sure we convert all fields to numeric\n",
    "loan=loan.convert_objects(convert_numeric=True)\n",
    "\n",
    "loan.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#OK great, let's now get our X and y. We know that interest rate is y.\n",
    "#Pandas is fantastic, all you need to do is use .values to get the data in numpy format\n",
    "y=loan.int_rate.values\n",
    "\n",
    "#Let's remove y from the df so we can get X\n",
    "del loan['int_rate']\n",
    "X=loan.values\n",
    "\n",
    "#Now, the train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Great, in no time we have grabbed an unknown dataset from the web, munged it using Pandas and now have ready-to-go\n",
    "#training and test numpy arrays for running the GBRT regressor. Let's go!\n",
    "\n",
    "#WARNING - THIS MIGHT TAKE A WHILE TO RUN. TRY ADJUSTING parameters such as n_jobs (jobs to run in parallel, before \n",
    "#increasing this make sure your system can handle it), n_iter for ShuffleSplit (in the function definition) and reducing \n",
    "#number of values being tried for max_depth/n_estimators.\n",
    "\n",
    "#SELECT INTERRUPT IN THE MENU AND PRESS INTERRUPT KERNEL IF YOU NEEDD TO STOP EXECUTION\n",
    "\n",
    "param_grid={'n_estimators':[100],#,500,1000],\n",
    "            'learning_rate': [0.1,0.05,0.02],# 0.01],\n",
    "            'max_depth':[4,6], \n",
    "            'min_samples_leaf':[3,5,9,17], \n",
    "            'max_features':[1.0,0.3,0.1]\n",
    "           }\n",
    "n_jobs=4\n",
    "\n",
    "#Let's fit GBRT to the digits training dataset by calling the function we just created.\n",
    "cv,best_est=GradientBooster(param_grid, n_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#OK great, so we got back the best estimator parameters as follows:\n",
    "print(\"Best Estimator Parameters\")\n",
    "print(\"---------------------------\")\n",
    "print (\"n_estimators:\", best_est.n_estimators)\n",
    "print (\"max_depth:\", best_est.max_depth)\n",
    "print (\"Learning Rate:\", best_est.learning_rate)\n",
    "print (\"min_samples_leaf:\", best_est.min_samples_leaf)\n",
    "print (\"max_features:\", best_est.max_features)\n",
    "\n",
    "print (\"Train R-squared:\", best_est.score(X_train,y_train))\n",
    "\n",
    "#The training R-Squared is almost 1.0 which indicates we can understand 99% of the variance in the data as well as\n",
    "#there's a chance we might overfit. Let's see with the learning curves below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#OK we'll now call the plot_learning_curve module by feeding it the estimator (best estimator returned from GS) \n",
    "#and train/cv sets.\n",
    "\n",
    "#The module simply runs the estimator multiple times on subsets of the data provided and plots the train and cv scores.\n",
    "#Note that we're feeding the best parameters we've learned from GridSearchCV to the estimator now.\n",
    "#We may need to adjust the hyperparameters further if there is overfitting (or underfitting, though unlikely)\n",
    "title = \"Learning Curves (Gradient Boosted Regression Trees)\" \n",
    "estimator = GradientBoostingRegressor(n_estimators=best_est.n_estimators, max_depth=best_est.max_depth,\n",
    "                                      learning_rate=best_est.learning_rate, min_samples_leaf=best_est.min_samples_leaf,\n",
    "                                      max_features=best_est.max_features)\n",
    "plot_learning_curve(estimator, title, X_train, y_train, cv=cv, n_jobs=n_jobs)\n",
    "plt.show()\n",
    "\n",
    "#OK yes, there is some overfitting there. We can see the training scores in red almost close to 1.0 and the cv scores\n",
    "#trying its best to reach it as the number of examples increases. This is what happens during overfitting. To address\n",
    "#overfitting, GBRT basically has the following parameters we can fine tune: Learning Rate, Max Depth, Min Samples leaf and\n",
    "#Max features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#the typical recommended values of Max depth is 4 to 6, so lets leave it at 4. Let's try increasing the min\n",
    "#samples leaf parameter, this basically enforces a lower bound on the number of samples in any given leaf.\n",
    "min_samples_leaf=9\n",
    "\n",
    "title = \"Learning Curves (Gradient Boosted Regression Trees), min_samples_leaf=9\" \n",
    "estimator = GradientBoostingRegressor(n_estimators=best_est.n_estimators, max_depth=best_est.max_depth,\n",
    "                                      learning_rate=best_est.learning_rate, min_samples_leaf=min_samples_leaf,\n",
    "                                      max_features=best_est.max_features)\n",
    "plot_learning_curve(estimator, title, X_train, y_train, cv=cv, n_jobs=n_jobs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Let's try reducing the max features parameter. This enforces an upper bound of the maximum number of features to use\n",
    "#for training. It's supposed to work well when n_features>30. We'll also remove min samples leaf for this run.\n",
    "max_features=0.5\n",
    "\n",
    "title = \"Learning Curves (Gradient Boosted Regression Trees), max_features=50%\" \n",
    "estimator = GradientBoostingRegressor(n_estimators=best_est.n_estimators, max_depth=best_est.max_depth,\n",
    "                                      learning_rate=best_est.learning_rate, max_features=max_features)\n",
    "plot_learning_curve(estimator, title, X_train, y_train, cv=cv, n_jobs=n_jobs)\n",
    "plt.show()\n",
    "\n",
    "#Nope that didn't quite improve the cv score either. What happens if we reduce learning rate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The lower the learning rate is the more the number of trees we need to train. This is because the rate at which we train\n",
    "#is simply, well, reduced.\n",
    "learning_rate=.01\n",
    "n_estimators=1000\n",
    "\n",
    "title = \"Learning Curves (Gradient Boosted Regression Trees), 1000 Trees at learning rate .01\"\n",
    "estimator = GradientBoostingRegressor(n_estimators=n_estimators, max_depth=best_est.max_depth,\n",
    "                                      learning_rate=learning_rate, min_samples_leaf=best_est.min_samples_leaf,\n",
    "                                      max_features=best_est.max_features)\n",
    "plot_learning_curve(estimator, title, X_train, y_train, cv=cv, n_jobs=n_jobs)\n",
    "plt.show()\n",
    "\n",
    "#Perhaps that improved it a tiny little bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Before we try anything else, I would like to explore one of the beautiful advantages of growing trees. And that is to\n",
    "#capture feature importances. Now that we have a publicly available loan application collection (though anonymous), it makes\n",
    "#me really curious to see what impacts the interest rate for a loan application the most.\n",
    "\n",
    "#Let's take a look\n",
    "\n",
    "#Calling fit on the estimator so we can look at feature_importances.\n",
    "estimator.fit(X_train, y_train)\n",
    "\n",
    "# Calculate the feature ranking - Top 10\n",
    "importances = estimator.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "print \"Lending Club Loan Data - Top 10 Important Features\\n\"\n",
    "\n",
    "for f in range(10):\n",
    "    print(\"%d. %s   (%f)\" % (f + 1, loan.columns[indices[f]], importances[indices[f]]))\n",
    "    \n",
    "#Plot the feature importances of the forest\n",
    "indices=indices[:10]\n",
    "plt.figure()\n",
    "plt.title(\"Top 10 Feature importances\")\n",
    "plt.bar(range(10), importances[indices],\n",
    "       color=\"r\", align=\"center\")\n",
    "plt.xticks(range(10), loan.columns[indices], fontsize=14, rotation=45)\n",
    "plt.xlim([-1, 10])\n",
    "plt.show()\n",
    "\n",
    "#Mean Feature Importance\n",
    "print \"Mean Feature Importance %.6f\" %np.mean(importances)\n",
    "\n",
    "#Interesting, the total amount of interest received to date is the top most influencer for getting a better interest rate.\n",
    "#Good for the lenders eh? Pay more interest, we'll give you a cut on the interest rate. Of course!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Can we actually trim (like before) and get a better result? Perhaps not, but who's to stop us from trying.\n",
    "title = \"Learning Curves (Gradient Boosted Regression Trees) - Trimmed features to > 1% importance\" \n",
    "\n",
    "#Dropping all parameters except n_estimators and learning_rate since we're going to trim the features anyway.\n",
    "estimator = GradientBoostingRegressor(n_estimators=best_est.n_estimators, learning_rate=best_est.learning_rate)\n",
    "\n",
    "#Calling fit on the estimator so we can transform the X matrices.\n",
    "estimator.fit(X_train, y_train)\n",
    "\n",
    "#Trimming feature matrices to include only those features that are more important than the mean of all importances.\n",
    "X_train_trim=estimator.transform(X_train, threshold=.01)\n",
    "\n",
    "#Trimming test as well in case we end up going with this model as final.\n",
    "X_test_trim=estimator.transform(X_test, threshold=.01)\n",
    "\n",
    "#Re-plotting Learning cruves.\n",
    "plot_learning_curve(estimator, title, X_train, y_train, cv=cv, n_jobs=n_jobs)\n",
    "plt.show()\n",
    "\n",
    "#Nope, the curve looks like it overfits less, but look at the cv score, in all our fancy attempts it never really crossed\n",
    "#that ~0.8 R-squared barrier. That tells me, we actually have a decent model at hand and also that a 0.9+ R-squared value is\n",
    "#not always possible, atleast in real time. Let's wrap this up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
